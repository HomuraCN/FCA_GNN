{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc2c157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 数据加载完成 ---\n",
      "训练节点数: 90, 验证节点数: 30, 测试节点数: 30\n",
      "\n",
      "--- 开始训练 ---\n",
      "Epoch: 020, Loss: 0.1459, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 0.9667\n",
      "Epoch: 040, Loss: 0.0179, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 0.9667\n",
      "Epoch: 060, Loss: 0.0066, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 0.9667\n",
      "Epoch: 080, Loss: 0.0091, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 0.9667\n",
      "Epoch: 100, Loss: 0.0200, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 0.9667\n",
      "Epoch: 120, Loss: 0.0341, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 0.9667\n",
      "Epoch: 140, Loss: 0.0240, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 0.9667\n",
      "Epoch: 160, Loss: 0.0085, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 0.9667\n",
      "Epoch: 180, Loss: 0.0165, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 0.9667\n",
      "Epoch: 200, Loss: 0.0263, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 0.9667\n",
      "--- 训练完成 ---\n",
      "最终测试集准确率: 0.9667\n",
      "\n",
      "TensorBoard 日志已写入 'runs' 文件夹。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# --- 实例化 SummaryWriter ---\n",
    "# 创建一个新的文件夹来存放本次实验的日志\n",
    "writer = SummaryWriter('../runs/iris_fca_gnn_multi_curve')\n",
    "\n",
    "# --- 数据加载与预处理 (与之前相同) ---\n",
    "features_path = '../data/iris.data.cleaned.csv'\n",
    "x_numpy = np.loadtxt(features_path, delimiter=',')\n",
    "x = torch.tensor(x_numpy, dtype=torch.float)\n",
    "\n",
    "adj_matrix_path = '../data/iris_A_plus.csv'\n",
    "a_plus_numpy = np.loadtxt(adj_matrix_path, delimiter=',')\n",
    "a_plus = torch.tensor(a_plus_numpy, dtype=torch.float)\n",
    "threshold = 10\n",
    "a_plus[a_plus <= threshold] = 0\n",
    "a_plus.fill_diagonal_(0)\n",
    "edge_index, edge_attr = dense_to_sparse(a_plus)\n",
    "\n",
    "labels_path = '../data/iris.data'\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "iris_df = pd.read_csv(labels_path, header=None, names=column_names)\n",
    "species_labels = iris_df['species'].values\n",
    "encoder = LabelEncoder()\n",
    "y_numpy = encoder.fit_transform(species_labels)\n",
    "y = torch.tensor(y_numpy, dtype=torch.long)\n",
    "\n",
    "num_nodes = x.shape[0]\n",
    "if num_nodes != len(y):\n",
    "    y = y[:num_nodes]\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "# --- 数据划分：训练(60%)、验证(20%)、测试(20%) ---\n",
    "num_train = int(num_nodes * 0.6)\n",
    "num_val = int(num_nodes * 0.2)\n",
    "num_test = num_nodes - num_train - num_val\n",
    "indices = torch.randperm(num_nodes)\n",
    "\n",
    "data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.train_mask[indices[:num_train]] = True\n",
    "data.val_mask[indices[num_train:num_train + num_val]] = True\n",
    "data.test_mask[indices[num_train + num_val:]] = True\n",
    "\n",
    "print(\"--- 数据加载完成 ---\")\n",
    "print(f\"训练节点数: {data.train_mask.sum().item()}, 验证节点数: {data.val_mask.sum().item()}, 测试节点数: {data.test_mask.sum().item()}\")\n",
    "\n",
    "# --- GNN 模型定义 (与之前相同) ---\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# --- 训练与评估 ---\n",
    "model = GCN(num_node_features=data.num_node_features, num_classes=len(np.unique(y_numpy)))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 只记录训练集的Loss\n",
    "    writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "    return loss.item()\n",
    "\n",
    "# --- 【修改】评估函数现在也计算并记录Loss ---\n",
    "def evaluate(epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        \n",
    "        # --- 计算 Loss ---\n",
    "        train_loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "        test_loss = criterion(out[data.test_mask], data.y[data.test_mask])\n",
    "        \n",
    "        # --- 计算 Accuracy ---\n",
    "        correct_train = pred[data.train_mask] == data.y[data.train_mask]\n",
    "        train_acc = int(correct_train.sum()) / int(data.train_mask.sum())\n",
    "        \n",
    "        correct_val = pred[data.val_mask] == data.y[data.val_mask]\n",
    "        val_acc = int(correct_val.sum()) / int(data.val_mask.sum())\n",
    "        \n",
    "        correct_test = pred[data.test_mask] == data.y[data.test_mask]\n",
    "        test_acc = int(correct_test.sum()) / int(data.test_mask.sum())\n",
    "\n",
    "        # --- 将所有指标记录到 TensorBoard ---\n",
    "        # 使用相同的 \"Loss\" 标签头，将三条线画在同一个Loss图里\n",
    "        writer.add_scalar('Loss/validation', val_loss.item(), epoch)\n",
    "        writer.add_scalar('Loss/test', test_loss.item(), epoch)\n",
    "        \n",
    "        # 使用相同的 \"Accuracy\" 标签头，将三条线画在同一个Accuracy图里\n",
    "        writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/validation', val_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_acc, epoch)\n",
    "        \n",
    "        return train_acc, val_acc, test_acc, train_loss.item()\n",
    "\n",
    "print(\"\\n--- 开始训练 ---\")\n",
    "for epoch in range(1, 201):\n",
    "    # train()函数现在只返回loss，不再计算精度，避免重复计算\n",
    "    loss = train(epoch) \n",
    "    \n",
    "    # 在每个 epoch 后都进行评估\n",
    "    train_acc, val_acc, test_acc, _ = evaluate(epoch)\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# 获取最后一个 epoch 的测试精度作为最终结果\n",
    "final_test_acc = evaluate(200)[2] \n",
    "print(f'--- 训练完成 ---')\n",
    "print(f'最终测试集准确率: {final_test_acc:.4f}')\n",
    "print(\"\\nTensorBoard 日志已写入 'runs' 文件夹。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47904126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
