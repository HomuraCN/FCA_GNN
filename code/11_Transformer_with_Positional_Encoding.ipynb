{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc0fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import TransformerConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse, get_laplacian, to_scipy_sparse_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy.sparse.linalg import eigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63989d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 超参数配置 (新增 pos_encoding_dim) ---\n",
    "hparams = {\n",
    "    'dataset': 'car',\n",
    "    'threshold_pos': 500,\n",
    "    'threshold_neg': 20000,\n",
    "    'hidden_channels': 16,\n",
    "    'heads': 4,\n",
    "    'pos_encoding_dim': 8,  # 【新增】为每个图计算8维的位置编码\n",
    "    'learning_rate': 0.005,\n",
    "    'weight_decay': 5e-4,\n",
    "    'epochs': 150,\n",
    "    'dropout': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b485a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 日志将保存在: ../runs/car_transformer_pe_d=8_20250926-145830\n"
     ]
    }
   ],
   "source": [
    "# --- 2. TensorBoard 设置 ---\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "log_dir_name = f\"../runs/{hparams['dataset']}_transformer_pe_d={hparams['pos_encoding_dim']}_{timestamp}\"\n",
    "writer = SummaryWriter(log_dir_name)\n",
    "print(f\"TensorBoard 日志将保存在: {log_dir_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c1709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 【核心修改】新增位置编码计算函数 ---\n",
    "def get_laplacian_positional_encoding(edge_index, num_nodes, pos_encoding_dim):\n",
    "    \"\"\"计算拉普拉斯特征向量位置编码\"\"\"\n",
    "    # 转换为 SciPy 稀疏矩阵\n",
    "    adj = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes)\n",
    "    \n",
    "    # 计算归一化拉普拉斯矩阵\n",
    "    from sklearn.utils.extmath import safe_sparse_dot\n",
    "    from scipy.sparse import spdiags\n",
    "    \n",
    "    n_nodes = adj.shape[0]\n",
    "    adj = adj.astype(float)\n",
    "    \n",
    "    # 计算度矩阵的逆平方根\n",
    "    d = np.array(adj.sum(axis=1)).flatten()\n",
    "    d_inv_sqrt = 1. / np.sqrt(d)\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_inv_sqrt_matrix = spdiags(d_inv_sqrt, 0, n_nodes, n_nodes)\n",
    "    \n",
    "    # I - D^-1/2 * A * D^-1/2\n",
    "    laplacian = spdiags(np.ones(n_nodes), 0, n_nodes, n_nodes) - d_inv_sqrt_matrix @ adj @ d_inv_sqrt_matrix\n",
    "\n",
    "    # 特征分解，寻找最小的 k 个特征值对应的特征向量\n",
    "    # k 设为 pos_encoding_dim + 1 是因为第一个特征向量（对应0特征值）通常是常数，需要忽略\n",
    "    try:\n",
    "        # 'SM' 表示寻找绝对值最小的特征值\n",
    "        _, eigvecs = eigs(laplacian, k=pos_encoding_dim + 1, which='SM', tol=1e-5)\n",
    "        eigvecs = np.real(eigvecs[:, 1:]) # 忽略第一个特征向量\n",
    "    except Exception as e:\n",
    "        print(f\"特征分解失败: {e}。使用随机向量作为备用。\")\n",
    "        eigvecs = np.random.rand(num_nodes, pos_encoding_dim)\n",
    "\n",
    "    return torch.from_numpy(eigvecs.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15baa217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 数据加载与预处理函数 (修改以加入位置编码) ---\n",
    "def load_and_prepare_data(dataset_name, threshold_pos, threshold_neg, pos_encoding_dim):\n",
    "    base_path = f'../data/{dataset_name}/'\n",
    "    \n",
    "    # ... (加载 x_features, a_plus_pos, a_plus_neg 的代码与之前相同) ...\n",
    "    features_path = f\"{base_path}{dataset_name}.data.cleaned.csv\"\n",
    "    x_numpy = np.loadtxt(features_path, delimiter=',')\n",
    "    x_features = torch.tensor(x_numpy, dtype=torch.float)\n",
    "    num_nodes = x_features.shape[0]\n",
    "\n",
    "    adj_matrix_pos_path = f\"{base_path}{dataset_name}_A_plus_UG.csv\"\n",
    "    a_plus_pos_numpy = np.loadtxt(adj_matrix_pos_path, delimiter=',')\n",
    "    a_plus_pos = torch.tensor(a_plus_pos_numpy, dtype=torch.float)\n",
    "    a_plus_pos[a_plus_pos <= threshold_pos] = 0\n",
    "    a_plus_pos.fill_diagonal_(0)\n",
    "    edge_index_pos, _ = dense_to_sparse(a_plus_pos)\n",
    "\n",
    "    adj_matrix_neg_path = f\"{base_path}{dataset_name}_A_negative_UG.csv\"\n",
    "    a_plus_neg_numpy = np.loadtxt(adj_matrix_neg_path, delimiter=',')\n",
    "    a_plus_neg = torch.tensor(a_plus_neg_numpy, dtype=torch.float)\n",
    "    a_plus_neg[a_plus_neg <= threshold_neg] = 0\n",
    "    a_plus_neg.fill_diagonal_(0)\n",
    "    edge_index_neg, _ = dense_to_sparse(a_plus_neg)\n",
    "\n",
    "    # --- 【核心修改】计算并拼接位置编码 ---\n",
    "    print(\"正在计算正概念图的位置编码...\")\n",
    "    pos_enc_pos = get_laplacian_positional_encoding(edge_index_pos, num_nodes, pos_encoding_dim)\n",
    "    \n",
    "    print(\"正在计算负概念图的位置编码...\")\n",
    "    pos_enc_neg = get_laplacian_positional_encoding(edge_index_neg, num_nodes, pos_encoding_dim)\n",
    "\n",
    "    # 将原始特征与两种位置编码拼接\n",
    "    x_enhanced = torch.cat([x_features, pos_enc_pos, pos_enc_neg], dim=1)\n",
    "    print(f\"原始特征维度: {x_features.shape[1]}\")\n",
    "    print(f\"增强后特征维度: {x_enhanced.shape[1]}\")\n",
    "\n",
    "    # ... (加载标签 y 和数据划分的代码与之前相同) ...\n",
    "    labels_path = f\"{base_path}{dataset_name}.data\"\n",
    "    if dataset_name == 'car':\n",
    "        column_names = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
    "        df = pd.read_csv(labels_path, header=None, names=column_names)\n",
    "        labels_numpy = df['class'].values\n",
    "    else:\n",
    "        df = pd.read_csv(f\"{base_path}{dataset_name}.data.csv\")\n",
    "        labels_numpy = df.iloc[:, -1].values\n",
    "        \n",
    "    encoder = LabelEncoder()\n",
    "    y_numpy = encoder.fit_transform(labels_numpy)\n",
    "    y = torch.tensor(y_numpy, dtype=torch.long)\n",
    "    if num_nodes != len(y): y = y[:num_nodes]\n",
    "\n",
    "    # 【修改】Data对象现在使用增强后的特征 x_enhanced\n",
    "    data = Data(x=x_enhanced, y=y,\n",
    "                edge_index_pos=edge_index_pos,\n",
    "                edge_index_neg=edge_index_neg)\n",
    "\n",
    "    num_train = int(num_nodes * 0.6)\n",
    "    num_val = int(num_nodes * 0.2)\n",
    "    indices = torch.randperm(num_nodes)\n",
    "    data.train_mask = torch.zeros(num_nodes, dtype=torch.bool); data.train_mask[indices[:num_train]] = True\n",
    "    data.val_mask = torch.zeros(num_nodes, dtype=torch.bool); data.val_mask[indices[num_train:num_train + num_val]] = True\n",
    "    data.test_mask = torch.zeros(num_nodes, dtype=torch.bool); data.test_mask[indices[num_train + num_val:]] = True\n",
    "    \n",
    "    return data, len(np.unique(y_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "819e21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. 定义模型 (输入维度 in_channels 会改变) ---\n",
    "class DualConceptTransformer(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=1, dropout=0.5):\n",
    "        super(DualConceptTransformer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.pos_conv = TransformerConv(in_channels, hidden_channels, heads=heads)\n",
    "        self.neg_conv = TransformerConv(in_channels, hidden_channels, heads=heads)\n",
    "        self.fusion_layer = nn.Linear(hidden_channels * heads * 2, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index_pos, edge_index_neg):\n",
    "        h_pos = self.pos_conv(x, edge_index_pos)\n",
    "        h_pos = F.relu(h_pos)\n",
    "        h_pos = F.dropout(h_pos, p=self.dropout, training=self.training)\n",
    "        \n",
    "        h_neg = self.neg_conv(x, edge_index_neg)\n",
    "        h_neg = F.relu(h_neg)\n",
    "        h_neg = F.dropout(h_neg, p=self.dropout, training=self.training)\n",
    "        \n",
    "        h_combined = torch.cat([h_pos, h_neg], dim=1)\n",
    "        out = self.fusion_layer(h_combined)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c1d9d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在计算正概念图的位置编码...\n",
      "正在计算负概念图的位置编码...\n",
      "原始特征维度: 25\n",
      "增强后特征维度: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WSQ\\AppData\\Local\\Temp\\ipykernel_107696\\2626197306.py:16: RuntimeWarning: divide by zero encountered in divide\n",
      "  d_inv_sqrt = 1. / np.sqrt(d)\n"
     ]
    }
   ],
   "source": [
    "# --- 6. 实例化数据和模型 ---\n",
    "data, num_classes = load_and_prepare_data(hparams['dataset'], \n",
    "                                          hparams['threshold_pos'], \n",
    "                                          hparams['threshold_neg'],\n",
    "                                          hparams['pos_encoding_dim'])\n",
    "\n",
    "# 【修改】模型的 in_channels 现在是增强后的特征维度\n",
    "model = DualConceptTransformer(in_channels=data.num_node_features, \n",
    "                               hidden_channels=hparams['hidden_channels'], \n",
    "                               out_channels=num_classes,\n",
    "                               heads=hparams['heads'],\n",
    "                               dropout=hparams['dropout'])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams['learning_rate'], weight_decay=hparams['weight_decay'])\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "986651c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. 训练与评估函数 (与之前相同) ---\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index_pos, data.edge_index_neg)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index_pos, data.edge_index_neg)\n",
    "        pred = out.argmax(dim=1)\n",
    "        \n",
    "        train_acc = (pred[data.train_mask] == data.y[data.train_mask]).sum().item() / data.train_mask.sum().item()\n",
    "        val_acc = (pred[data.val_mask] == data.y[data.val_mask]).sum().item() / data.val_mask.sum().item()\n",
    "        test_acc = (pred[data.test_mask] == data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "\n",
    "        writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/validation', val_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_acc, epoch)\n",
    "        \n",
    "        return train_acc, val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c253cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始训练 (带位置编码的双概念格 Graph Transformer) ---\n",
      "Epoch: 001, Loss: 1.4115, Train Acc: 0.8427, Val Acc: 0.8058, Test Acc: 0.8588\n",
      "Epoch: 002, Loss: 1.2205, Train Acc: 0.8388, Val Acc: 0.7942, Test Acc: 0.8617\n",
      "Epoch: 003, Loss: 1.0470, Train Acc: 0.8282, Val Acc: 0.7739, Test Acc: 0.8530\n",
      "Epoch: 004, Loss: 0.8856, Train Acc: 0.8195, Val Acc: 0.7507, Test Acc: 0.8415\n",
      "Epoch: 005, Loss: 0.7484, Train Acc: 0.8147, Val Acc: 0.7449, Test Acc: 0.8357\n",
      "Epoch: 006, Loss: 0.6325, Train Acc: 0.8272, Val Acc: 0.7681, Test Acc: 0.8444\n",
      "Epoch: 007, Loss: 0.5433, Train Acc: 0.8504, Val Acc: 0.8000, Test Acc: 0.8646\n",
      "Epoch: 008, Loss: 0.4829, Train Acc: 0.8639, Val Acc: 0.8348, Test Acc: 0.8876\n",
      "Epoch: 009, Loss: 0.4429, Train Acc: 0.8678, Val Acc: 0.8435, Test Acc: 0.8876\n",
      "Epoch: 010, Loss: 0.3909, Train Acc: 0.8736, Val Acc: 0.8435, Test Acc: 0.8905\n",
      "Epoch: 011, Loss: 0.3630, Train Acc: 0.9044, Val Acc: 0.8754, Test Acc: 0.9135\n",
      "Epoch: 012, Loss: 0.3306, Train Acc: 0.9218, Val Acc: 0.9014, Test Acc: 0.9395\n",
      "Epoch: 013, Loss: 0.2976, Train Acc: 0.9218, Val Acc: 0.9014, Test Acc: 0.9452\n",
      "Epoch: 014, Loss: 0.2831, Train Acc: 0.9218, Val Acc: 0.9014, Test Acc: 0.9452\n",
      "Epoch: 015, Loss: 0.2647, Train Acc: 0.9218, Val Acc: 0.9014, Test Acc: 0.9452\n",
      "Epoch: 016, Loss: 0.2450, Train Acc: 0.9218, Val Acc: 0.9014, Test Acc: 0.9452\n",
      "Epoch: 017, Loss: 0.2312, Train Acc: 0.9218, Val Acc: 0.9014, Test Acc: 0.9452\n",
      "Epoch: 018, Loss: 0.2120, Train Acc: 0.9218, Val Acc: 0.9014, Test Acc: 0.9452\n",
      "Epoch: 019, Loss: 0.1947, Train Acc: 0.9218, Val Acc: 0.9014, Test Acc: 0.9452\n",
      "Epoch: 020, Loss: 0.1796, Train Acc: 0.9218, Val Acc: 0.9014, Test Acc: 0.9452\n",
      "Epoch: 021, Loss: 0.1671, Train Acc: 0.9228, Val Acc: 0.9043, Test Acc: 0.9452\n",
      "Epoch: 022, Loss: 0.1467, Train Acc: 0.9402, Val Acc: 0.9072, Test Acc: 0.9510\n",
      "Epoch: 023, Loss: 0.1380, Train Acc: 0.9585, Val Acc: 0.9275, Test Acc: 0.9625\n",
      "Epoch: 024, Loss: 0.1258, Train Acc: 0.9653, Val Acc: 0.9449, Test Acc: 0.9654\n",
      "Epoch: 025, Loss: 0.1170, Train Acc: 0.9759, Val Acc: 0.9565, Test Acc: 0.9712\n",
      "Epoch: 026, Loss: 0.1093, Train Acc: 0.9913, Val Acc: 0.9739, Test Acc: 0.9885\n",
      "Epoch: 027, Loss: 0.1071, Train Acc: 0.9981, Val Acc: 0.9884, Test Acc: 0.9971\n",
      "Epoch: 028, Loss: 0.1034, Train Acc: 1.0000, Val Acc: 0.9971, Test Acc: 0.9971\n",
      "Epoch: 029, Loss: 0.0929, Train Acc: 1.0000, Val Acc: 0.9971, Test Acc: 1.0000\n",
      "Epoch: 030, Loss: 0.0906, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 031, Loss: 0.0876, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 032, Loss: 0.0845, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 033, Loss: 0.0793, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 034, Loss: 0.0703, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 035, Loss: 0.0737, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 036, Loss: 0.0663, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 037, Loss: 0.0668, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 038, Loss: 0.0573, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 039, Loss: 0.0524, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 040, Loss: 0.0507, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 041, Loss: 0.0513, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 042, Loss: 0.0461, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 043, Loss: 0.0465, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 044, Loss: 0.0402, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 045, Loss: 0.0368, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 046, Loss: 0.0348, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 047, Loss: 0.0343, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 048, Loss: 0.0312, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 049, Loss: 0.0271, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 050, Loss: 0.0261, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 051, Loss: 0.0251, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 052, Loss: 0.0285, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 053, Loss: 0.0218, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 054, Loss: 0.0228, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 055, Loss: 0.0198, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 056, Loss: 0.0207, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 057, Loss: 0.0171, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 058, Loss: 0.0194, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 059, Loss: 0.0174, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 060, Loss: 0.0197, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 061, Loss: 0.0128, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 062, Loss: 0.0141, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 063, Loss: 0.0138, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 064, Loss: 0.0114, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 065, Loss: 0.0104, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 066, Loss: 0.0152, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 067, Loss: 0.0123, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 068, Loss: 0.0103, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 069, Loss: 0.0101, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 070, Loss: 0.0103, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 071, Loss: 0.0117, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 072, Loss: 0.0092, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 073, Loss: 0.0087, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 074, Loss: 0.0109, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 075, Loss: 0.0099, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 076, Loss: 0.0089, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 077, Loss: 0.0076, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 078, Loss: 0.0089, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 079, Loss: 0.0079, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 080, Loss: 0.0084, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 081, Loss: 0.0056, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 082, Loss: 0.0064, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 083, Loss: 0.0059, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 084, Loss: 0.0062, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 085, Loss: 0.0051, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 086, Loss: 0.0057, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 087, Loss: 0.0055, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 088, Loss: 0.0054, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 089, Loss: 0.0048, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 090, Loss: 0.0056, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 091, Loss: 0.0053, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 092, Loss: 0.0071, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 093, Loss: 0.0055, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 094, Loss: 0.0048, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 095, Loss: 0.0058, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 096, Loss: 0.0056, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 097, Loss: 0.0047, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 098, Loss: 0.0048, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 099, Loss: 0.0042, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 100, Loss: 0.0055, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 101, Loss: 0.0044, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 102, Loss: 0.0054, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 103, Loss: 0.0044, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 104, Loss: 0.0048, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 105, Loss: 0.0048, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 106, Loss: 0.0044, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 107, Loss: 0.0042, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 108, Loss: 0.0038, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 109, Loss: 0.0048, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 110, Loss: 0.0046, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 111, Loss: 0.0039, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 112, Loss: 0.0031, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 113, Loss: 0.0040, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 114, Loss: 0.0048, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 115, Loss: 0.0041, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 116, Loss: 0.0039, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 117, Loss: 0.0043, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 118, Loss: 0.0042, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 119, Loss: 0.0032, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 120, Loss: 0.0043, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 121, Loss: 0.0033, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 122, Loss: 0.0033, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 123, Loss: 0.0042, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 124, Loss: 0.0041, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 125, Loss: 0.0032, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 126, Loss: 0.0034, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 127, Loss: 0.0034, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 128, Loss: 0.0053, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 129, Loss: 0.0035, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 130, Loss: 0.0037, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 131, Loss: 0.0035, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 132, Loss: 0.0044, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 133, Loss: 0.0034, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 134, Loss: 0.0031, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 135, Loss: 0.0029, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 136, Loss: 0.0034, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 137, Loss: 0.0034, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 138, Loss: 0.0028, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 139, Loss: 0.0033, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 140, Loss: 0.0045, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 141, Loss: 0.0035, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 142, Loss: 0.0047, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 143, Loss: 0.0036, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 144, Loss: 0.0029, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 145, Loss: 0.0047, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 146, Loss: 0.0038, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 147, Loss: 0.0032, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 148, Loss: 0.0027, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 149, Loss: 0.0041, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 150, Loss: 0.0029, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "--- 训练完成 ---\n",
      "最终测试集准确率: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# --- 8. 主训练循环 (与之前相同) ---\n",
    "print(\"\\n--- 开始训练 (带位置编码的双概念格 Graph Transformer) ---\")\n",
    "for epoch in range(1, hparams['epochs'] + 1):\n",
    "    loss = train(epoch)\n",
    "    if epoch % 1 == 0:\n",
    "        train_acc, val_acc, test_acc = evaluate(epoch)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "# --- 训练完成后 ---\n",
    "final_train_acc, final_val_acc, final_test_acc = evaluate(hparams['epochs'])\n",
    "print(f'--- 训练完成 ---')\n",
    "print(f'最终测试集准确率: {final_test_acc:.4f}')\n",
    "\n",
    "metrics = {'accuracy/final_train': final_train_acc, 'accuracy/final_validation': final_val_acc, 'accuracy/final_test': final_test_acc}\n",
    "writer.add_hparams(hparams, metrics)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f3504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
