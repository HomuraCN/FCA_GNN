{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11a6fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# 【核心修改】导入 TransformerConv 层\n",
    "from torch_geometric.nn import TransformerConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35ce229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 日志将保存在: ../runs/iris_transformer_tp=10_tn=40000_lr=0.005_wd=0.0005_20250926-140901\n"
     ]
    }
   ],
   "source": [
    "# --- 1. 超参数配置 (新增 heads) ---\n",
    "hparams = {\n",
    "    'dataset': 'iris',\n",
    "    'threshold_pos': 10,\n",
    "    'threshold_neg': 40000,\n",
    "    'hidden_channels': 16,\n",
    "    'heads': 4,  # Transformer的多头注意力头数\n",
    "    'learning_rate': 0.005,\n",
    "    'weight_decay': 5e-4,\n",
    "    'epochs': 100,\n",
    "    'dropout': 0.5\n",
    "}\n",
    "\n",
    "# --- 2. TensorBoard 设置 (与之前相同) ---\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "log_dir_name = f\"../runs/{hparams['dataset']}_transformer_tp={hparams['threshold_pos']}_tn={hparams['threshold_neg']}_lr={hparams['learning_rate']}_wd={hparams['weight_decay']}_{timestamp}\"\n",
    "writer = SummaryWriter(log_dir_name)\n",
    "print(f\"TensorBoard 日志将保存在: {log_dir_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2abbfc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 数据加载与预处理函数 (与之前相同) ---\n",
    "def load_and_prepare_data(dataset_name, threshold_pos, threshold_neg):\n",
    "    base_path = f'../data/{dataset_name}/'\n",
    "    \n",
    "    features_path = f\"{base_path}{dataset_name}.data.cleaned.csv\"\n",
    "    x_numpy = np.loadtxt(features_path, delimiter=',')\n",
    "    x_features = torch.tensor(x_numpy, dtype=torch.float)\n",
    "    num_nodes = x_features.shape[0]\n",
    "\n",
    "    adj_matrix_pos_path = f\"{base_path}{dataset_name}_A_plus_UG.csv\"\n",
    "    a_plus_pos_numpy = np.loadtxt(adj_matrix_pos_path, delimiter=',')\n",
    "    a_plus_pos = torch.tensor(a_plus_pos_numpy, dtype=torch.float)\n",
    "    a_plus_pos[a_plus_pos <= threshold_pos] = 0\n",
    "    a_plus_pos.fill_diagonal_(0)\n",
    "    edge_index_pos, edge_attr_pos = dense_to_sparse(a_plus_pos)\n",
    "\n",
    "    adj_matrix_neg_path = f\"{base_path}{dataset_name}_A_negative_UG.csv\"\n",
    "    a_plus_neg_numpy = np.loadtxt(adj_matrix_neg_path, delimiter=',')\n",
    "    a_plus_neg = torch.tensor(a_plus_neg_numpy, dtype=torch.float)\n",
    "    a_plus_neg[a_plus_neg <= threshold_neg] = 0\n",
    "    a_plus_neg.fill_diagonal_(0)\n",
    "    edge_index_neg, edge_attr_neg = dense_to_sparse(a_plus_neg)\n",
    "\n",
    "    labels_path = f\"{base_path}{dataset_name}.data\"\n",
    "    column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "    try:\n",
    "        df = pd.read_csv(labels_path, header=None, names=column_names)\n",
    "        labels_numpy = df['species'].values\n",
    "    except Exception: # For datasets like 'zoo' with different format\n",
    "        df = pd.read_csv(f\"{base_path}{dataset_name}.data.csv\")\n",
    "        labels_numpy = df.iloc[:, -1].values\n",
    "        \n",
    "    encoder = LabelEncoder()\n",
    "    y_numpy = encoder.fit_transform(labels_numpy)\n",
    "    y = torch.tensor(y_numpy, dtype=torch.long)\n",
    "    if num_nodes != len(y):\n",
    "        y = y[:num_nodes]\n",
    "\n",
    "    data = Data(x=x_features, y=y,\n",
    "                edge_index_pos=edge_index_pos, edge_attr_pos=edge_attr_pos,\n",
    "                edge_index_neg=edge_index_neg, edge_attr_neg=edge_attr_neg)\n",
    "\n",
    "    num_train = int(num_nodes * 0.6)\n",
    "    num_val = int(num_nodes * 0.2)\n",
    "    indices = torch.randperm(num_nodes)\n",
    "    data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    data.train_mask[indices[:num_train]] = True\n",
    "    data.val_mask[indices[num_train:num_train + num_val]] = True\n",
    "    data.test_mask[indices[num_train + num_val:]] = True\n",
    "    \n",
    "    return data, len(np.unique(y_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3628b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 【核心修改】定义双分支 Graph Transformer 模型 ---\n",
    "class DualConceptTransformer(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=1, dropout=0.5):\n",
    "        super(DualConceptTransformer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # 分支一：处理正概念格图的 Transformer 层\n",
    "        self.pos_conv = TransformerConv(in_channels, hidden_channels, heads=heads)\n",
    "        \n",
    "        # 分支二：处理负概念格图的 Transformer 层\n",
    "        self.neg_conv = TransformerConv(in_channels, hidden_channels, heads=heads)\n",
    "        \n",
    "        # 融合层\n",
    "        # 输入维度是两个分支隐藏层维度之和 (hidden_channels * heads * 2)\n",
    "        self.fusion_layer = nn.Linear(hidden_channels * heads * 2, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index_pos, edge_index_neg):\n",
    "        # --- 分支一前向传播 (正概念图) ---\n",
    "        # TransformerConv 只需要 x 和 edge_index，它会自己学习边的权重（注意力）\n",
    "        h_pos = self.pos_conv(x, edge_index_pos)\n",
    "        h_pos = F.relu(h_pos)\n",
    "        h_pos = F.dropout(h_pos, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # --- 分支二前向传播 (负概念图) ---\n",
    "        h_neg = self.neg_conv(x, edge_index_neg)\n",
    "        h_neg = F.relu(h_neg)\n",
    "        h_neg = F.dropout(h_neg, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # --- 特征融合 ---\n",
    "        h_combined = torch.cat([h_pos, h_neg], dim=1)\n",
    "        \n",
    "        # --- 通过融合层得到最终输出 ---\n",
    "        out = self.fusion_layer(h_combined)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4649c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. 实例化数据和模型 (与之前类似) ---\n",
    "data, num_classes = load_and_prepare_data(hparams['dataset'], hparams['threshold_pos'], hparams['threshold_neg'])\n",
    "\n",
    "model = DualConceptTransformer(in_channels=data.num_node_features, \n",
    "                               hidden_channels=hparams['hidden_channels'], \n",
    "                               out_channels=num_classes,\n",
    "                               heads=hparams['heads'],\n",
    "                               dropout=hparams['dropout'])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams['learning_rate'], weight_decay=hparams['weight_decay'])\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cca357d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. 训练与评估函数 (模型调用部分有修改) ---\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # 【修改】模型调用不再需要 edge_attr\n",
    "    out = model(data.x, data.edge_index_pos, data.edge_index_neg)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 【修改】模型调用不再需要 edge_attr\n",
    "        out = model(data.x, data.edge_index_pos, data.edge_index_neg)\n",
    "        pred = out.argmax(dim=1)\n",
    "        \n",
    "        train_acc = (pred[data.train_mask] == data.y[data.train_mask]).sum().item() / data.train_mask.sum().item()\n",
    "        val_acc = (pred[data.val_mask] == data.y[data.val_mask]).sum().item() / data.val_mask.sum().item()\n",
    "        test_acc = (pred[data.test_mask] == data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "\n",
    "        writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/validation', val_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_acc, epoch)\n",
    "        \n",
    "        return train_acc, val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d6df08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始训练 (双概念格 Graph Transformer) ---\n",
      "Epoch: 001, Loss: 1.0886, Train Acc: 0.7889, Val Acc: 0.8667, Test Acc: 0.7667\n",
      "Epoch: 002, Loss: 1.0083, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 1.0000\n",
      "Epoch: 003, Loss: 0.9236, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 1.0000\n",
      "Epoch: 004, Loss: 0.8293, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 1.0000\n",
      "Epoch: 005, Loss: 0.7472, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 1.0000\n",
      "Epoch: 006, Loss: 0.6487, Train Acc: 1.0000, Val Acc: 0.9667, Test Acc: 1.0000\n",
      "Epoch: 007, Loss: 0.5477, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 008, Loss: 0.4400, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 009, Loss: 0.3571, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 010, Loss: 0.2916, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 011, Loss: 0.1998, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 012, Loss: 0.1743, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 013, Loss: 0.1243, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 014, Loss: 0.0920, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 015, Loss: 0.0578, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 016, Loss: 0.0469, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 017, Loss: 0.0331, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 018, Loss: 0.0206, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 019, Loss: 0.0150, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 020, Loss: 0.0105, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 021, Loss: 0.0093, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 022, Loss: 0.0105, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 023, Loss: 0.0061, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 024, Loss: 0.0050, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 025, Loss: 0.0041, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 026, Loss: 0.0040, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 027, Loss: 0.0021, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 028, Loss: 0.0024, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 029, Loss: 0.0024, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 030, Loss: 0.0025, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 031, Loss: 0.0017, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 032, Loss: 0.0036, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 033, Loss: 0.0014, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 034, Loss: 0.0009, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 035, Loss: 0.0014, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 036, Loss: 0.0022, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 037, Loss: 0.0008, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 038, Loss: 0.0007, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 039, Loss: 0.0009, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 040, Loss: 0.0008, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 041, Loss: 0.0015, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 042, Loss: 0.0007, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 043, Loss: 0.0012, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 044, Loss: 0.0011, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 045, Loss: 0.0010, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 046, Loss: 0.0010, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 047, Loss: 0.0007, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 048, Loss: 0.0009, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 049, Loss: 0.0006, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 050, Loss: 0.0010, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 051, Loss: 0.0009, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 052, Loss: 0.0009, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 053, Loss: 0.0007, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 054, Loss: 0.0011, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 055, Loss: 0.0010, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 056, Loss: 0.0006, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 057, Loss: 0.0009, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 058, Loss: 0.0009, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 059, Loss: 0.0006, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 060, Loss: 0.0015, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 061, Loss: 0.0010, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 062, Loss: 0.0010, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 063, Loss: 0.0018, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 064, Loss: 0.0011, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 065, Loss: 0.0011, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 066, Loss: 0.0018, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 067, Loss: 0.0011, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 068, Loss: 0.0017, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 069, Loss: 0.0011, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 070, Loss: 0.0008, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 071, Loss: 0.0013, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 072, Loss: 0.0015, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 073, Loss: 0.0019, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 074, Loss: 0.0013, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 075, Loss: 0.0010, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 076, Loss: 0.0016, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 077, Loss: 0.0012, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 078, Loss: 0.0010, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 079, Loss: 0.0013, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 080, Loss: 0.0013, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 081, Loss: 0.0013, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 082, Loss: 0.0021, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 083, Loss: 0.0012, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 084, Loss: 0.0013, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 085, Loss: 0.0012, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 086, Loss: 0.0014, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 087, Loss: 0.0017, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 088, Loss: 0.0009, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 089, Loss: 0.0019, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 090, Loss: 0.0015, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 091, Loss: 0.0017, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 092, Loss: 0.0017, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 093, Loss: 0.0019, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 094, Loss: 0.0012, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 095, Loss: 0.0021, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 096, Loss: 0.0020, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 097, Loss: 0.0007, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 098, Loss: 0.0013, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 099, Loss: 0.0012, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 100, Loss: 0.0019, Train Acc: 1.0000, Val Acc: 1.0000, Test Acc: 1.0000\n",
      "--- 训练完成 ---\n",
      "最终测试集准确率 (双概念格分支 Transformer): 1.0000\n"
     ]
    }
   ],
   "source": [
    "# --- 7. 主训练循环 (与之前相同) ---\n",
    "print(\"\\n--- 开始训练 (双概念格 Graph Transformer) ---\")\n",
    "for epoch in range(1, hparams['epochs'] + 1):\n",
    "    loss = train(epoch)\n",
    "    if epoch % 1 == 0:\n",
    "        train_acc, val_acc, test_acc = evaluate(epoch)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "# --- 训练完成后 ---\n",
    "final_train_acc, final_val_acc, final_test_acc = evaluate(hparams['epochs'])\n",
    "print(f'--- 训练完成 ---')\n",
    "print(f'最终测试集准确率 (双概念格分支 Transformer): {final_test_acc:.4f}')\n",
    "\n",
    "metrics = {\n",
    "    'accuracy/final_train': final_train_acc,\n",
    "    'accuracy/final_validation': final_val_acc,\n",
    "    'accuracy/final_test': final_test_acc\n",
    "}\n",
    "\n",
    "writer.add_hparams(hparams, metrics)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5b680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
