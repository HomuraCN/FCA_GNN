{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99d1efd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始邻接矩阵中的非零元素数: 22500\n",
      "阈值化后邻接矩阵中的非零元素数: 653\n",
      "--- 数据加载完成 ---\n",
      "Data(x=[150, 126], edge_index=[2, 653], edge_attr=[653], y=[150], train_mask=[150], test_mask=[150])\n",
      "节点总数: 150\n",
      "训练节点数: 120\n",
      "测试节点数: 30\n",
      "类别数: 3\n",
      "\n",
      "--- 开始训练 ---\n",
      "Epoch: 020, Loss: 0.1560, Test Accuracy: 0.9667\n",
      "Epoch: 040, Loss: 0.0449, Test Accuracy: 0.9667\n",
      "Epoch: 060, Loss: 0.0285, Test Accuracy: 0.9667\n",
      "Epoch: 080, Loss: 0.0274, Test Accuracy: 0.9667\n",
      "Epoch: 100, Loss: 0.0182, Test Accuracy: 0.9667\n",
      "Epoch: 120, Loss: 0.0057, Test Accuracy: 0.9667\n",
      "Epoch: 140, Loss: 0.0271, Test Accuracy: 0.9667\n",
      "Epoch: 160, Loss: 0.0141, Test Accuracy: 0.9667\n",
      "Epoch: 180, Loss: 0.0268, Test Accuracy: 0.9667\n",
      "Epoch: 200, Loss: 0.0066, Test Accuracy: 0.9667\n",
      "--- 训练完成 ---\n",
      "最终测试集准确率: 0.9667\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- 1. 数据加载与预处理 ---\n",
    "\n",
    "# a) 加载节点特征矩阵 X (来自FCA处理后的二元上下文)\n",
    "features_path = '../data/iris.data.cleaned.csv'\n",
    "x_numpy = np.loadtxt(features_path, delimiter=',')\n",
    "x = torch.tensor(x_numpy, dtype=torch.float)\n",
    "\n",
    "# b) 加载邻接矩阵 A+ (来自FCA概念格) 并转换为 edge_index\n",
    "adj_matrix_path = '../data/iris_A_plus.csv'\n",
    "a_plus_numpy = np.loadtxt(adj_matrix_path, delimiter=',')\n",
    "a_plus = torch.tensor(a_plus_numpy, dtype=torch.float)\n",
    "# ==========================================================\n",
    "# ====================  【核心修改】 ====================\n",
    "#              让邻接矩阵变得稀疏\n",
    "# ==========================================================\n",
    "# 打印原始的边数\n",
    "print(f\"原始邻接矩阵中的非零元素数: {torch.count_nonzero(a_plus)}\")\n",
    "\n",
    "# 方法1：设置一个阈值，比如只保留权重 > 0 的连接\n",
    "threshold = 10\n",
    "a_plus[a_plus <= threshold] = 0\n",
    "\n",
    "# (可选) 移除自环 (一个节点到自身的连接)\n",
    "a_plus.fill_diagonal_(0)\n",
    "\n",
    "print(f\"阈值化后邻接矩阵中的非零元素数: {torch.count_nonzero(a_plus)}\")\n",
    "# ==========================================================\n",
    "\n",
    "# 转换成稀疏格式\n",
    "edge_index, edge_attr = dense_to_sparse(a_plus)\n",
    "\n",
    "# c) 从原始 iris.data 文件加载标签 y\n",
    "labels_path = '../data/iris.data'\n",
    "# 为 iris 数据集添加列名\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "iris_df = pd.read_csv(labels_path, header=None, names=column_names)\n",
    "\n",
    "# 提取最后一列的物种名\n",
    "species_labels = iris_df['species'].values\n",
    "\n",
    "# 将字符串标签转换为数值 (e.g., 'Iris-setosa' -> 0)\n",
    "encoder = LabelEncoder()\n",
    "y_numpy = encoder.fit_transform(species_labels)\n",
    "y = torch.tensor(y_numpy, dtype=torch.long)\n",
    "\n",
    "# 确保节点特征数量和标签数量一致\n",
    "# 注意：FCA去重后，节点数可能会减少，这里我们假设节点与原始数据行一一对应\n",
    "# 如果节点数少于原始数据行数，需要根据去重逻辑对齐标签\n",
    "num_nodes = x.shape[0]\n",
    "if num_nodes != len(y):\n",
    "    print(f\"警告: 特征矩阵的节点数 ({num_nodes}) 与标签数 ({len(y)}) 不匹配。\")\n",
    "    # 假设FCA的去重保留了每个唯一行第一次出现的位置，我们据此对齐标签\n",
    "    # 首先，获取去重前的原始二元上下文（需要Java代码生成或假设）\n",
    "    # 为简化起见，此处我们假设节点与原始数据一一对应，并截取标签以匹配节点数\n",
    "    # 在实际应用中，应保存去重时对象ID的映射关系\n",
    "    y = y[:num_nodes]\n",
    "    print(f\"已将标签截取为 {len(y)} 个以匹配节点数。\")\n",
    "\n",
    "\n",
    "# d) 创建 PyTorch Geometric 的 Data 对象\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "# e) 划分训练集和测试集 (4:1)\n",
    "num_train = int(num_nodes * 0.8)\n",
    "num_test = num_nodes - num_train\n",
    "\n",
    "# 创建一个乱序的索引\n",
    "indices = torch.randperm(num_nodes)\n",
    "\n",
    "# 创建训练和测试掩码 (mask)\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[indices[:num_train]] = True\n",
    "test_mask[indices[num_train:]] = True\n",
    "\n",
    "# 将掩码添加到 Data 对象中\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "\n",
    "print(\"--- 数据加载完成 ---\")\n",
    "print(data)\n",
    "print(f\"节点总数: {data.num_nodes}\")\n",
    "print(f\"训练节点数: {data.train_mask.sum().item()}\")\n",
    "print(f\"测试节点数: {data.test_mask.sum().item()}\")\n",
    "print(f\"类别数: {len(np.unique(y_numpy))}\")\n",
    "\n",
    "\n",
    "# --- 2. GNN 模型定义 ---\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        # 定义第一个GCN层，隐藏层维度设为16\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        # 定义第二个GCN层，输出维度为类别数\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # 第一层 GCN + ReLU 激活函数\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        # Dropout 可选，用于防止过拟合\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        # 第二层 GCN\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # 输出层通常接 LogSoftmax 用于 NLLLoss，或直接输出 logits 用于 CrossEntropyLoss\n",
    "        return x\n",
    "\n",
    "# --- 3. 训练与评估 ---\n",
    "\n",
    "# 实例化模型\n",
    "model = GCN(num_node_features=data.num_node_features, num_classes=len(np.unique(y_numpy)))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # 模型前向传播\n",
    "    out = model(data.x, data.edge_index)\n",
    "    # 只使用训练节点的输出来计算损失\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    # 在所有节点上进行预测\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    # 只使用测试节点的预测结果来计算准确率\n",
    "    correct = pred[data.test_mask] == data.y[data.test_mask]\n",
    "    acc = int(correct.sum()) / int(data.test_mask.sum())\n",
    "    return acc\n",
    "\n",
    "print(\"\\n--- 开始训练 ---\")\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 20 == 0:\n",
    "        test_acc = test()\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "final_test_acc = test()\n",
    "print(f'--- 训练完成 ---')\n",
    "print(f'最终测试集准确率: {final_test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723233f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
