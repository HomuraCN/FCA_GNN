{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3219597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime # 导入 datetime\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d1ad4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 日志将保存在: ../runs/zoo_tp=4000_tn=49000_lr=0.005_wd=0.0005_20250926-144126\n",
      "--- 正概念图 ---\n",
      "阈值化后保留 1288 条边。\n",
      "--- 负概念图 ---\n",
      "阈值化后保留 916 条边。\n"
     ]
    }
   ],
   "source": [
    "# In[2]:\n",
    "# =============================================================================\n",
    "# 单元格 2: 定义超参数、创建唯一日志目录、加载数据\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. 定义实验参数和超参数 ---\n",
    "data_name = 'zoo'\n",
    "\n",
    "# a) 数据处理超参数\n",
    "hparams = {\n",
    "    'threshold_pos': 4000,\n",
    "    'threshold_neg': 49000,\n",
    "    'learning_rate': 0.005,\n",
    "    'weight_decay': 5e-4,\n",
    "    'hidden_channels': 16,\n",
    "    'epochs': 150\n",
    "}\n",
    "\n",
    "# --- 2. 创建唯一的 TensorBoard 日志目录 ---\n",
    "# a) 将超参数格式化为字符串\n",
    "hparam_str = f\"tp={hparams['threshold_pos']}_tn={hparams['threshold_neg']}_lr={hparams['learning_rate']}_wd={hparams['weight_decay']}\"\n",
    "# b) 获取当前时间戳\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "# c) 组合成最终的日志目录\n",
    "log_dir = f\"../runs/{data_name}_{hparam_str}_{timestamp}\"\n",
    "\n",
    "# d) 实例化 SummaryWriter\n",
    "writer = SummaryWriter(log_dir)\n",
    "print(f\"TensorBoard 日志将保存在: {log_dir}\")\n",
    "\n",
    "\n",
    "# --- 3. 数据加载与预处理 ---\n",
    "\n",
    "# a) 加载节点特征 (两个分支共享相同的节点特征)\n",
    "features_path = '../data/' + data_name + '/' + data_name + '.data.cleaned.csv'\n",
    "x_numpy = np.loadtxt(features_path, delimiter=',')\n",
    "x_features = torch.tensor(x_numpy, dtype=torch.float)\n",
    "num_nodes = x_features.shape[0]\n",
    "\n",
    "# b) 加载并处理正概念格邻接矩阵 (分支一)\n",
    "adj_matrix_pos_path = '../data/' + data_name + '/' + data_name + '_A_plus_UG.csv'\n",
    "a_plus_pos_numpy = np.loadtxt(adj_matrix_pos_path, delimiter=',')\n",
    "a_plus_pos = torch.tensor(a_plus_pos_numpy, dtype=torch.float)\n",
    "a_plus_pos[a_plus_pos <= hparams['threshold_pos']] = 0\n",
    "a_plus_pos.fill_diagonal_(0)\n",
    "pos_edge_num = torch.count_nonzero(a_plus_pos).item() # 计算边数\n",
    "edge_index_pos, edge_attr_pos = dense_to_sparse(a_plus_pos)\n",
    "print(f\"--- 正概念图 ---\")\n",
    "print(f\"阈值化后保留 {pos_edge_num} 条边。\")\n",
    "\n",
    "\n",
    "# c) 加载并处理负概念格邻接矩阵 (分支二)\n",
    "adj_matrix_neg_path = '../data/' + data_name + '/' + data_name + '_A_negative_UG.csv'\n",
    "a_plus_neg_numpy = np.loadtxt(adj_matrix_neg_path, delimiter=',')\n",
    "a_plus_neg = torch.tensor(a_plus_neg_numpy, dtype=torch.float)\n",
    "a_plus_neg[a_plus_neg <= hparams['threshold_neg']] = 0\n",
    "a_plus_neg.fill_diagonal_(0)\n",
    "neg_edge_num = torch.count_nonzero(a_plus_neg).item() # 计算边数\n",
    "edge_index_neg, edge_attr_neg = dense_to_sparse(a_plus_neg)\n",
    "print(f\"--- 负概念图 ---\")\n",
    "print(f\"阈值化后保留 {neg_edge_num} 条边。\")\n",
    "\n",
    "# d) 将计算出的边数也加入超参数字典，用于记录\n",
    "hparams['pos_edge_num'] = pos_edge_num\n",
    "hparams['neg_edge_num'] = neg_edge_num\n",
    "\n",
    "# e) 加载标签 y\n",
    "labels_path = '../data/' + data_name + '/' + data_name + '.data'\n",
    "column_names = [\n",
    "    \"animal_name\", \"hair\", \"feathers\", \"eggs\", \"milk\", \"airborne\", \n",
    "    \"aquatic\", \"predator\", \"toothed\", \"backbone\", \"breathes\", \n",
    "    \"venomous\", \"fins\", \"legs\", \"tail\", \"domestic\", \"catsize\", \"type\"\n",
    "]\n",
    "data_df = pd.read_csv(labels_path, header=None, names=column_names)\n",
    "species_labels = data_df['type'].values\n",
    "encoder = LabelEncoder()\n",
    "y_numpy = encoder.fit_transform(species_labels)\n",
    "y = torch.tensor(y_numpy, dtype=torch.long)\n",
    "if num_nodes != len(y):\n",
    "    y = y[:num_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eebbfb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 数据加载完成 (双概念格分支模型) ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[101, 43], y=[101], edge_index_pos=[2, 2118], edge_attr_pos=[2118], edge_index_neg=[2, 916], edge_attr_neg=[916], train_mask=[101], val_mask=[101], test_mask=[101])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e) 创建包含所有图信息的 Data 对象\n",
    "data = Data(x=x_features, y=y,\n",
    "            edge_index_pos=edge_index_pos, edge_attr_pos=edge_attr_pos,\n",
    "            edge_index_neg=edge_index_neg, edge_attr_neg=edge_attr_neg)\n",
    "\n",
    "# f) 数据划分\n",
    "num_train = int(num_nodes * 0.6)\n",
    "num_val = int(num_nodes * 0.2)\n",
    "num_test = num_nodes - num_train - num_val\n",
    "indices = torch.randperm(num_nodes)\n",
    "data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.train_mask[indices[:num_train]] = True\n",
    "data.val_mask[indices[num_train:num_train + num_val]] = True\n",
    "data.test_mask[indices[num_train + num_val:]] = True\n",
    "\n",
    "print(\"\\n--- 数据加载完成 (双概念格分支模型) ---\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4acc3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 定义双概念格分支 GNN 模型 (DualConceptGCN) ---\n",
    "class DualConceptGCN(nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
    "        super(DualConceptGCN, self).__init__()\n",
    "        \n",
    "        # 分支一：处理正概念格图\n",
    "        self.pos_conv = GCNConv(num_node_features, hidden_channels)\n",
    "        \n",
    "        # 分支二：处理负概念格图\n",
    "        self.neg_conv = GCNConv(num_node_features, hidden_channels)\n",
    "        \n",
    "        # 融合层\n",
    "        self.fusion_layer = nn.Linear(hidden_channels * 2, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index_pos, edge_attr_pos, edge_index_neg, edge_attr_neg):\n",
    "        # --- 分支一前向传播 (正概念图) ---\n",
    "        h_pos = self.pos_conv(x, edge_index_pos, edge_attr_pos)\n",
    "        h_pos = F.relu(h_pos)\n",
    "        h_pos = F.dropout(h_pos, p=0.5, training=self.training)\n",
    "        \n",
    "        # --- 分支二前向传播 (负概念图) ---\n",
    "        h_neg = self.neg_conv(x, edge_index_neg, edge_attr_neg)\n",
    "        h_neg = F.relu(h_neg)\n",
    "        h_neg = F.dropout(h_neg, p=0.5, training=self.training)\n",
    "        \n",
    "        # --- 特征融合 ---\n",
    "        h_combined = torch.cat([h_pos, h_neg], dim=1)\n",
    "        \n",
    "        # --- 通过融合层得到最终输出 ---\n",
    "        out = self.fusion_layer(h_combined)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ae5c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始训练 (双概念格分支 GNN) ---\n",
      "Epoch: 001, Loss: 2.0871, Train Acc: 0.0167, Val Acc: 0.1500, Test Acc: 0.0952\n",
      "Epoch: 002, Loss: 2.0130, Train Acc: 0.1167, Val Acc: 0.3000, Test Acc: 0.0952\n",
      "Epoch: 003, Loss: 1.8661, Train Acc: 0.4500, Val Acc: 0.5000, Test Acc: 0.1905\n",
      "Epoch: 004, Loss: 1.7803, Train Acc: 0.6833, Val Acc: 0.6000, Test Acc: 0.3810\n",
      "Epoch: 005, Loss: 1.7276, Train Acc: 0.8000, Val Acc: 0.6500, Test Acc: 0.5714\n",
      "Epoch: 006, Loss: 1.6535, Train Acc: 0.8000, Val Acc: 0.7000, Test Acc: 0.5714\n",
      "Epoch: 007, Loss: 1.5695, Train Acc: 0.7833, Val Acc: 0.7000, Test Acc: 0.5714\n",
      "Epoch: 008, Loss: 1.5585, Train Acc: 0.7833, Val Acc: 0.7000, Test Acc: 0.5714\n",
      "Epoch: 009, Loss: 1.4996, Train Acc: 0.7667, Val Acc: 0.7000, Test Acc: 0.5714\n",
      "Epoch: 010, Loss: 1.4374, Train Acc: 0.7333, Val Acc: 0.7000, Test Acc: 0.5238\n",
      "Epoch: 011, Loss: 1.3623, Train Acc: 0.7167, Val Acc: 0.7000, Test Acc: 0.5238\n",
      "Epoch: 012, Loss: 1.3331, Train Acc: 0.7167, Val Acc: 0.7000, Test Acc: 0.5238\n",
      "Epoch: 013, Loss: 1.2466, Train Acc: 0.7667, Val Acc: 0.7000, Test Acc: 0.5714\n",
      "Epoch: 014, Loss: 1.2368, Train Acc: 0.7667, Val Acc: 0.7000, Test Acc: 0.5714\n",
      "Epoch: 015, Loss: 1.1649, Train Acc: 0.7667, Val Acc: 0.7000, Test Acc: 0.5714\n",
      "Epoch: 016, Loss: 1.1013, Train Acc: 0.7833, Val Acc: 0.7000, Test Acc: 0.5714\n",
      "Epoch: 017, Loss: 1.0297, Train Acc: 0.8000, Val Acc: 0.7000, Test Acc: 0.5714\n",
      "Epoch: 018, Loss: 1.1053, Train Acc: 0.8167, Val Acc: 0.7500, Test Acc: 0.6190\n",
      "Epoch: 019, Loss: 0.9200, Train Acc: 0.8167, Val Acc: 0.8000, Test Acc: 0.6667\n",
      "Epoch: 020, Loss: 0.8616, Train Acc: 0.8500, Val Acc: 0.8000, Test Acc: 0.7143\n",
      "Epoch: 021, Loss: 0.8598, Train Acc: 0.8500, Val Acc: 0.8000, Test Acc: 0.7143\n",
      "Epoch: 022, Loss: 0.8303, Train Acc: 0.8500, Val Acc: 0.8000, Test Acc: 0.7143\n",
      "Epoch: 023, Loss: 0.8018, Train Acc: 0.8500, Val Acc: 0.8000, Test Acc: 0.7143\n",
      "Epoch: 024, Loss: 0.8323, Train Acc: 0.8500, Val Acc: 0.8000, Test Acc: 0.7143\n",
      "Epoch: 025, Loss: 0.7003, Train Acc: 0.8500, Val Acc: 0.8500, Test Acc: 0.7143\n",
      "Epoch: 026, Loss: 0.6518, Train Acc: 0.8667, Val Acc: 0.8500, Test Acc: 0.7143\n",
      "Epoch: 027, Loss: 0.7019, Train Acc: 0.8667, Val Acc: 0.8500, Test Acc: 0.7143\n",
      "Epoch: 028, Loss: 0.7414, Train Acc: 0.8667, Val Acc: 0.8500, Test Acc: 0.7143\n",
      "Epoch: 029, Loss: 0.7043, Train Acc: 0.8667, Val Acc: 0.8500, Test Acc: 0.7143\n",
      "Epoch: 030, Loss: 0.6495, Train Acc: 0.8667, Val Acc: 0.8500, Test Acc: 0.7143\n",
      "Epoch: 031, Loss: 0.6227, Train Acc: 0.8667, Val Acc: 0.8500, Test Acc: 0.7143\n",
      "Epoch: 032, Loss: 0.6027, Train Acc: 0.8667, Val Acc: 0.8500, Test Acc: 0.7619\n",
      "Epoch: 033, Loss: 0.5378, Train Acc: 0.8667, Val Acc: 0.8500, Test Acc: 0.7619\n",
      "Epoch: 034, Loss: 0.6146, Train Acc: 0.8833, Val Acc: 0.8500, Test Acc: 0.7619\n",
      "Epoch: 035, Loss: 0.5470, Train Acc: 0.8833, Val Acc: 0.8500, Test Acc: 0.7619\n",
      "Epoch: 036, Loss: 0.4777, Train Acc: 0.9000, Val Acc: 0.8500, Test Acc: 0.7619\n",
      "Epoch: 037, Loss: 0.4844, Train Acc: 0.9167, Val Acc: 0.8500, Test Acc: 0.8095\n",
      "Epoch: 038, Loss: 0.5017, Train Acc: 0.9167, Val Acc: 0.8500, Test Acc: 0.8095\n",
      "Epoch: 039, Loss: 0.5549, Train Acc: 0.9167, Val Acc: 0.8500, Test Acc: 0.8095\n",
      "Epoch: 040, Loss: 0.5138, Train Acc: 0.9167, Val Acc: 0.9500, Test Acc: 0.8095\n",
      "Epoch: 041, Loss: 0.4369, Train Acc: 0.9167, Val Acc: 0.9500, Test Acc: 0.8095\n",
      "Epoch: 042, Loss: 0.4656, Train Acc: 0.9167, Val Acc: 0.9000, Test Acc: 0.8095\n",
      "Epoch: 043, Loss: 0.4519, Train Acc: 0.9167, Val Acc: 0.9000, Test Acc: 0.8095\n",
      "Epoch: 044, Loss: 0.4071, Train Acc: 0.9333, Val Acc: 0.9000, Test Acc: 0.8095\n",
      "Epoch: 045, Loss: 0.4287, Train Acc: 0.9500, Val Acc: 0.9000, Test Acc: 0.8571\n",
      "Epoch: 046, Loss: 0.4018, Train Acc: 0.9500, Val Acc: 0.9000, Test Acc: 0.8571\n",
      "Epoch: 047, Loss: 0.3708, Train Acc: 0.9500, Val Acc: 0.9000, Test Acc: 0.9048\n",
      "Epoch: 048, Loss: 0.4972, Train Acc: 0.9500, Val Acc: 0.9000, Test Acc: 0.9048\n",
      "Epoch: 049, Loss: 0.4365, Train Acc: 0.9667, Val Acc: 0.9000, Test Acc: 0.9048\n",
      "Epoch: 050, Loss: 0.3652, Train Acc: 0.9667, Val Acc: 0.9000, Test Acc: 0.9048\n",
      "Epoch: 051, Loss: 0.3724, Train Acc: 0.9667, Val Acc: 0.9000, Test Acc: 0.9048\n",
      "Epoch: 052, Loss: 0.4386, Train Acc: 0.9667, Val Acc: 0.9000, Test Acc: 0.9048\n",
      "Epoch: 053, Loss: 0.3122, Train Acc: 0.9667, Val Acc: 0.9000, Test Acc: 0.9048\n",
      "Epoch: 054, Loss: 0.4037, Train Acc: 0.9667, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 055, Loss: 0.4149, Train Acc: 0.9667, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 056, Loss: 0.4150, Train Acc: 0.9667, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 057, Loss: 0.2883, Train Acc: 0.9667, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 058, Loss: 0.3386, Train Acc: 0.9667, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 059, Loss: 0.3611, Train Acc: 0.9667, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 060, Loss: 0.2910, Train Acc: 0.9667, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 061, Loss: 0.2502, Train Acc: 0.9833, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 062, Loss: 0.2800, Train Acc: 0.9833, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 063, Loss: 0.2547, Train Acc: 0.9833, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 064, Loss: 0.2717, Train Acc: 0.9833, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 065, Loss: 0.2644, Train Acc: 0.9833, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 066, Loss: 0.2408, Train Acc: 0.9833, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 067, Loss: 0.2403, Train Acc: 0.9833, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 068, Loss: 0.2896, Train Acc: 0.9833, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 069, Loss: 0.2129, Train Acc: 0.9833, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 070, Loss: 0.2533, Train Acc: 0.9833, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 071, Loss: 0.3034, Train Acc: 0.9833, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 072, Loss: 0.2727, Train Acc: 0.9833, Val Acc: 0.9500, Test Acc: 0.9048\n",
      "Epoch: 073, Loss: 0.1783, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 074, Loss: 0.2295, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 075, Loss: 0.1603, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 076, Loss: 0.1990, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 077, Loss: 0.1423, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 078, Loss: 0.2046, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 079, Loss: 0.1888, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 080, Loss: 0.2438, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 081, Loss: 0.2111, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 082, Loss: 0.2087, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 083, Loss: 0.1585, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 084, Loss: 0.2176, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 085, Loss: 0.1630, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 086, Loss: 0.1452, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 087, Loss: 0.1903, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 088, Loss: 0.1896, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 089, Loss: 0.1616, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 090, Loss: 0.1993, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 091, Loss: 0.1390, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 092, Loss: 0.1301, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 093, Loss: 0.1313, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 094, Loss: 0.2206, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 095, Loss: 0.1269, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 096, Loss: 0.1544, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 097, Loss: 0.1039, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 098, Loss: 0.1951, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 099, Loss: 0.0937, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 100, Loss: 0.1711, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 101, Loss: 0.2017, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 102, Loss: 0.1089, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 103, Loss: 0.1413, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 104, Loss: 0.1517, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 105, Loss: 0.0985, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 106, Loss: 0.0931, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 107, Loss: 0.1197, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 108, Loss: 0.1363, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 109, Loss: 0.1398, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 110, Loss: 0.1286, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 111, Loss: 0.0756, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 112, Loss: 0.1372, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 113, Loss: 0.1754, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 114, Loss: 0.1288, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 115, Loss: 0.1015, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 116, Loss: 0.1143, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 117, Loss: 0.1004, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 118, Loss: 0.1015, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 119, Loss: 0.0836, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 120, Loss: 0.1263, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 121, Loss: 0.0782, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 122, Loss: 0.1044, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 123, Loss: 0.0700, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 124, Loss: 0.1252, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 125, Loss: 0.0818, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 126, Loss: 0.1091, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 127, Loss: 0.0950, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 128, Loss: 0.0873, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 129, Loss: 0.0799, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 130, Loss: 0.1136, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 131, Loss: 0.1008, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 132, Loss: 0.1319, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 133, Loss: 0.0856, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 134, Loss: 0.1105, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 135, Loss: 0.0512, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 136, Loss: 0.0558, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 137, Loss: 0.1335, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 138, Loss: 0.0964, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 139, Loss: 0.0666, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 140, Loss: 0.0621, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 141, Loss: 0.0634, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 142, Loss: 0.0683, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 143, Loss: 0.0805, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 144, Loss: 0.0738, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 145, Loss: 0.0708, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 146, Loss: 0.0741, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 147, Loss: 0.1295, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 148, Loss: 0.0529, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 149, Loss: 0.0544, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "Epoch: 150, Loss: 0.0828, Train Acc: 1.0000, Val Acc: 0.9500, Test Acc: 0.9524\n",
      "--- 训练完成 ---\n",
      "最终测试集准确率 (双概念格分支 GNN): 0.9524\n",
      "\n",
      "TensorBoard 日志和超参数已写入 '../runs/zoo_tp=3000_tn=49000_lr=0.005_wd=0.0005_20250925-190614' 文件夹。\n"
     ]
    }
   ],
   "source": [
    "# --- 3. 训练与评估 ---\n",
    "model = DualConceptGCN(num_node_features=data.num_node_features, \n",
    "                       hidden_channels=hparams['hidden_channels'], \n",
    "                       num_classes=len(np.unique(y_numpy)))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams['learning_rate'], weight_decay=hparams['weight_decay'])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index_pos, data.edge_attr_pos, \n",
    "                data.edge_index_neg, data.edge_attr_neg)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index_pos, data.edge_attr_pos, \n",
    "                    data.edge_index_neg, data.edge_attr_neg)\n",
    "        pred = out.argmax(dim=1)\n",
    "        \n",
    "        train_acc = (pred[data.train_mask] == data.y[data.train_mask]).sum().item() / data.train_mask.sum().item()\n",
    "        val_acc = (pred[data.val_mask] == data.y[data.val_mask]).sum().item() / data.val_mask.sum().item()\n",
    "        test_acc = (pred[data.test_mask] == data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "\n",
    "        writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/validation', val_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_acc, epoch)\n",
    "        \n",
    "        return train_acc, val_acc, test_acc\n",
    "\n",
    "print(\"\\n--- 开始训练 (双概念格分支 GNN) ---\")\n",
    "for epoch in range(1, hparams['epochs'] + 1):\n",
    "    loss = train(epoch)\n",
    "    if epoch % 1 == 0:\n",
    "        train_acc, val_acc, test_acc = evaluate(epoch)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "# --- 训练完成后 ---\n",
    "# 1. 获取最终的性能指标\n",
    "final_train_acc, final_val_acc, final_test_acc = evaluate(hparams['epochs'])\n",
    "print(f'--- 训练完成 ---')\n",
    "print(f'最终测试集准确率 (双概念格分支 GNN): {final_test_acc:.4f}')\n",
    "\n",
    "# 2. 定义需要记录的最终指标\n",
    "metrics = {\n",
    "    'accuracy/final_train': final_train_acc,\n",
    "    'accuracy/final_validation': final_val_acc,\n",
    "    'accuracy/final_test': final_test_acc\n",
    "}\n",
    "\n",
    "# 3. 【新增】调用 add_hparams 记录本次运行的超参数和结果\n",
    "writer.add_hparams(hparams, metrics)\n",
    "\n",
    "# 4. 关闭 writer\n",
    "writer.close()\n",
    "print(f\"\\nTensorBoard 日志和超参数已写入 '{log_dir}' 文件夹。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
