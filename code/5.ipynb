{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac5771ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始邻接矩阵中的非零元素数: 22500\n",
      "阈值化后邻接矩阵中的非零元素数: 653\n",
      "--- 数据加载完成 ---\n",
      "Data(x=[150, 126], edge_index=[2, 653], edge_attr=[653], y=[150], train_mask=[150], test_mask=[150])\n",
      "节点总数: 150\n",
      "训练节点数: 120\n",
      "测试节点数: 30\n",
      "类别数: 3\n",
      "\n",
      "--- 开始训练 ---\n",
      "Epoch: 020, Loss: 0.1859, Train Acc: 0.9917, Test Acc: 1.0000\n",
      "Epoch: 040, Loss: 0.0620, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 060, Loss: 0.0321, Train Acc: 1.0000, Test Acc: 0.9667\n",
      "Epoch: 080, Loss: 0.0181, Train Acc: 1.0000, Test Acc: 0.9667\n",
      "Epoch: 100, Loss: 0.0156, Train Acc: 1.0000, Test Acc: 0.9667\n",
      "Epoch: 120, Loss: 0.0161, Train Acc: 1.0000, Test Acc: 0.9667\n",
      "Epoch: 140, Loss: 0.0441, Train Acc: 1.0000, Test Acc: 0.9667\n",
      "Epoch: 160, Loss: 0.0087, Train Acc: 1.0000, Test Acc: 0.9667\n",
      "Epoch: 180, Loss: 0.0187, Train Acc: 1.0000, Test Acc: 0.9667\n",
      "Epoch: 200, Loss: 0.0220, Train Acc: 1.0000, Test Acc: 0.9667\n",
      "--- 训练完成 ---\n",
      "最终测试集准确率: 0.9667\n",
      "\n",
      "TensorBoard 日志已写入 'runs' 文件夹。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 1. 导入 SummaryWriter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# --- 实例化 SummaryWriter ---\n",
    "# 这会创建一个 'runs/iris_fca_gnn' 文件夹来存放日志\n",
    "writer = SummaryWriter('../runs/iris_fca_gnn')\n",
    "\n",
    "# --- 1. 数据加载与预处理 (与你的代码相同) ---\n",
    "\n",
    "# a) 加载节点特征矩阵 X (来自FCA处理后的二元上下文)\n",
    "features_path = '../data/iris.data.cleaned.csv'\n",
    "x_numpy = np.loadtxt(features_path, delimiter=',')\n",
    "x = torch.tensor(x_numpy, dtype=torch.float)\n",
    "\n",
    "# b) 加载邻接矩阵 A+ (来自FCA概念格) 并转换为 edge_index\n",
    "adj_matrix_path = '../data/iris_A_plus.csv'\n",
    "a_plus_numpy = np.loadtxt(adj_matrix_path, delimiter=',')\n",
    "a_plus = torch.tensor(a_plus_numpy, dtype=torch.float)\n",
    "# ==========================================================\n",
    "# ====================  【核心修改】 ====================\n",
    "#              让邻接矩阵变得稀疏\n",
    "# ==========================================================\n",
    "print(f\"原始邻接矩阵中的非零元素数: {torch.count_nonzero(a_plus)}\")\n",
    "threshold = 10\n",
    "a_plus[a_plus <= threshold] = 0\n",
    "a_plus.fill_diagonal_(0)\n",
    "print(f\"阈值化后邻接矩阵中的非零元素数: {torch.count_nonzero(a_plus)}\")\n",
    "# ==========================================================\n",
    "edge_index, edge_attr = dense_to_sparse(a_plus)\n",
    "\n",
    "# c) 从原始 iris.data 文件加载标签 y\n",
    "labels_path = '../data/iris.data'\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "iris_df = pd.read_csv(labels_path, header=None, names=column_names)\n",
    "species_labels = iris_df['species'].values\n",
    "encoder = LabelEncoder()\n",
    "y_numpy = encoder.fit_transform(species_labels)\n",
    "y = torch.tensor(y_numpy, dtype=torch.long)\n",
    "\n",
    "num_nodes = x.shape[0]\n",
    "if num_nodes != len(y):\n",
    "    print(f\"警告: 特征矩阵的节点数 ({num_nodes}) 与标签数 ({len(y)}) 不匹配。\")\n",
    "    y = y[:num_nodes]\n",
    "    print(f\"已将标签截取为 {len(y)} 个以匹配节点数。\")\n",
    "\n",
    "# d) 创建 PyTorch Geometric 的 Data 对象\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "# e) 划分训练集和测试集 (4:1)\n",
    "num_train = int(num_nodes * 0.8)\n",
    "num_test = num_nodes - num_train\n",
    "indices = torch.randperm(num_nodes)\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[indices[:num_train]] = True\n",
    "test_mask[indices[num_train:]] = True\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "print(\"--- 数据加载完成 ---\")\n",
    "print(data)\n",
    "print(f\"节点总数: {data.num_nodes}\")\n",
    "print(f\"训练节点数: {data.train_mask.sum().item()}\")\n",
    "print(f\"测试节点数: {data.test_mask.sum().item()}\")\n",
    "print(f\"类别数: {len(np.unique(y_numpy))}\")\n",
    "\n",
    "\n",
    "# --- 2. GNN 模型定义 (与你的代码相同) ---\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# --- 3. 【修改】训练与评估 ---\n",
    "model = GCN(num_node_features=data.num_node_features, num_classes=len(np.unique(y_numpy)))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 将 train 和 test 函数修改为接收 epoch 参数\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 2. 在训练函数中记录 Loss\n",
    "    writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(epoch):\n",
    "    \"\"\"一个通用的评估函数，可以计算任何数据集划分的准确率\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        \n",
    "        # 计算训练集准确率\n",
    "        correct_train = pred[data.train_mask] == data.y[data.train_mask]\n",
    "        train_acc = int(correct_train.sum()) / int(data.train_mask.sum())\n",
    "        \n",
    "        # 计算测试集准确率\n",
    "        correct_test = pred[data.test_mask] == data.y[data.test_mask]\n",
    "        test_acc = int(correct_test.sum()) / int(data.test_mask.sum())\n",
    "\n",
    "        # 3. 在评估函数中记录训练和测试准确率\n",
    "        writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_acc, epoch)\n",
    "        \n",
    "        return train_acc, test_acc\n",
    "\n",
    "print(\"\\n--- 开始训练 ---\")\n",
    "for epoch in range(1, 201):\n",
    "    loss = train(epoch)\n",
    "    \n",
    "    # 在每个 epoch 后都进行评估，以便记录每一轮的精度\n",
    "    train_acc, test_acc = evaluate(epoch)\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        # 打印时，我们直接使用评估函数返回的结果\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "# 4. 训练结束后关闭 writer\n",
    "writer.close()\n",
    "\n",
    "final_test_acc = evaluate(200)[1] # 获取最后一个 epoch 的测试精度\n",
    "print(f'--- 训练完成 ---')\n",
    "print(f'最终测试集准确率: {final_test_acc:.4f}')\n",
    "print(\"\\nTensorBoard 日志已写入 'runs' 文件夹。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779e649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
