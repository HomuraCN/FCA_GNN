{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c658b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在生成随机图结构 ---\n",
      "已生成一个包含 650 条随机边的图。\n",
      "\n",
      "--- 数据加载完成 (使用随机图) ---\n",
      "Data(x=[150, 126], edge_index=[2, 650], edge_attr=[650], y=[150], train_mask=[150], val_mask=[150], test_mask=[150])\n",
      "训练节点数: 90, 验证节点数: 30, 测试节点数: 30\n",
      "\n",
      "--- 开始训练 (使用随机图) ---\n",
      "Epoch: 020, Loss: 0.9324, Train Acc: 0.6556, Val Acc: 0.3333, Test Acc: 0.3333\n",
      "Epoch: 040, Loss: 0.6931, Train Acc: 0.7444, Val Acc: 0.4000, Test Acc: 0.2667\n",
      "Epoch: 060, Loss: 0.5413, Train Acc: 0.8111, Val Acc: 0.4000, Test Acc: 0.3000\n",
      "Epoch: 080, Loss: 0.4809, Train Acc: 0.9000, Val Acc: 0.3333, Test Acc: 0.3000\n",
      "Epoch: 100, Loss: 0.3773, Train Acc: 0.9222, Val Acc: 0.3667, Test Acc: 0.3667\n",
      "Epoch: 120, Loss: 0.4011, Train Acc: 0.9889, Val Acc: 0.3333, Test Acc: 0.3333\n",
      "Epoch: 140, Loss: 0.3269, Train Acc: 0.9778, Val Acc: 0.3000, Test Acc: 0.3667\n",
      "Epoch: 160, Loss: 0.3287, Train Acc: 1.0000, Val Acc: 0.3000, Test Acc: 0.3333\n",
      "Epoch: 180, Loss: 0.3127, Train Acc: 1.0000, Val Acc: 0.3000, Test Acc: 0.3333\n",
      "Epoch: 200, Loss: 0.2342, Train Acc: 1.0000, Val Acc: 0.2667, Test Acc: 0.3333\n",
      "--- 训练完成 ---\n",
      "最终测试集准确率 (使用随机图): 0.3333\n",
      "\n",
      "TensorBoard 日志已写入 'runs/iris_random_gnn_comparison' 文件夹。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# --- 实例化 SummaryWriter ---\n",
    "# 为这个新的对照实验创建一个独立的日志文件夹\n",
    "writer = SummaryWriter('../runs/iris_random_gnn_comparison')\n",
    "\n",
    "# --- 1. 数据加载与预处理 ---\n",
    "\n",
    "# a) 加载节点特征矩阵 X (这部分保持不变)\n",
    "features_path = '../data/iris.data.cleaned.csv'\n",
    "x_numpy = np.loadtxt(features_path, delimiter=',')\n",
    "x = torch.tensor(x_numpy, dtype=torch.float)\n",
    "num_nodes = x.shape[0]\n",
    "\n",
    "# =================================================================\n",
    "# ============  【核心修改】替换为随机邻接矩阵  ============\n",
    "# =================================================================\n",
    "# 在 7.ipynb 中，经过阈值化处理后，有效的边数（非零元素）是 653。\n",
    "# 为了进行公平比较，我们也生成一个包含大约 653 条随机边的图。\n",
    "\n",
    "print(f\"--- 正在生成随机图结构 ---\")\n",
    "num_edges_from_fca = 653  # 从 7.ipynb 的输出中得知\n",
    "\n",
    "# 随机生成边的起点和终点\n",
    "# torch.randint(low, high, size)\n",
    "# 我们生成 num_edges_from_fca 条边\n",
    "source_nodes = torch.randint(0, num_nodes, (num_edges_from_fca,))\n",
    "target_nodes = torch.randint(0, num_nodes, (num_edges_from_fca,))\n",
    "\n",
    "# 组合成 edge_index 格式\n",
    "random_edge_index = torch.stack([source_nodes, target_nodes], dim=0)\n",
    "\n",
    "# (可选) 为随机边生成随机权重，或者统一设为1\n",
    "# 这里我们统一设为1，因为边的存在性比权重更重要\n",
    "random_edge_attr = torch.ones(num_edges_from_fca, dtype=torch.float)\n",
    "\n",
    "# (可选) 移除自环，确保没有节点指向自己\n",
    "is_self_loop = random_edge_index[0] == random_edge_index[1]\n",
    "random_edge_index = random_edge_index[:, ~is_self_loop]\n",
    "random_edge_attr = random_edge_attr[~is_self_loop]\n",
    "\n",
    "print(f\"已生成一个包含 {random_edge_index.shape[1]} 条随机边的图。\")\n",
    "# =================================================================\n",
    "# =================================================================\n",
    "\n",
    "# c) 加载标签 y (这部分保持不变)\n",
    "labels_path = '../data/iris.data'\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "iris_df = pd.read_csv(labels_path, header=None, names=column_names)\n",
    "species_labels = iris_df['species'].values\n",
    "encoder = LabelEncoder()\n",
    "y_numpy = encoder.fit_transform(species_labels)\n",
    "y = torch.tensor(y_numpy, dtype=torch.long)\n",
    "\n",
    "if num_nodes != len(y):\n",
    "    y = y[:num_nodes]\n",
    "\n",
    "# d) 创建 Data 对象，但使用随机生成的 edge_index 和 edge_attr\n",
    "data = Data(x=x, edge_index=random_edge_index, edge_attr=random_edge_attr, y=y)\n",
    "\n",
    "# e) 数据划分 (保持不变)\n",
    "num_train = int(num_nodes * 0.6)\n",
    "num_val = int(num_nodes * 0.2)\n",
    "num_test = num_nodes - num_train - num_val\n",
    "indices = torch.randperm(num_nodes)\n",
    "\n",
    "data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.train_mask[indices[:num_train]] = True\n",
    "data.val_mask[indices[num_train:num_train + num_val]] = True\n",
    "data.test_mask[indices[num_train + num_val:]] = True\n",
    "\n",
    "print(\"\\n--- 数据加载完成 (使用随机图) ---\")\n",
    "print(data)\n",
    "print(f\"训练节点数: {data.train_mask.sum().item()}, 验证节点数: {data.val_mask.sum().item()}, 测试节点数: {data.test_mask.sum().item()}\")\n",
    "\n",
    "# --- GNN 模型定义 (保持不变) ---\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# --- 训练与评估 (保持不变) ---\n",
    "model = GCN(num_node_features=data.num_node_features, num_classes=len(np.unique(y_numpy)))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    writer.add_scalar('Loss/train_random_adj', loss.item(), epoch)\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        \n",
    "        train_acc = (pred[data.train_mask] == data.y[data.train_mask]).sum().item() / data.train_mask.sum().item()\n",
    "        val_acc = (pred[data.val_mask] == data.y[data.val_mask]).sum().item() / data.val_mask.sum().item()\n",
    "        test_acc = (pred[data.test_mask] == data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "\n",
    "        writer.add_scalar('Accuracy/train_random_adj', train_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/validation_random_adj', val_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/test_random_adj', test_acc, epoch)\n",
    "        \n",
    "        return train_acc, val_acc, test_acc\n",
    "\n",
    "print(\"\\n--- 开始训练 (使用随机图) ---\")\n",
    "for epoch in range(1, 201):\n",
    "    loss = train(epoch)\n",
    "    if epoch % 20 == 0:\n",
    "        train_acc, val_acc, test_acc = evaluate(epoch)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "writer.close()\n",
    "\n",
    "final_test_acc = evaluate(200)[2]\n",
    "print(f'--- 训练完成 ---')\n",
    "print(f'最终测试集准确率 (使用随机图): {final_test_acc:.4f}')\n",
    "print(\"\\nTensorBoard 日志已写入 'runs/iris_random_gnn_comparison' 文件夹。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c13ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
